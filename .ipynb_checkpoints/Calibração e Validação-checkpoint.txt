```python
# SMAP para Bacia de Camargos - Calibração e Validação
```

```python
#### To-Do
```

```python
- Ouvir aula (conferir se existe um método padrão para calibração)
- Identify and explain the most important parameters for accuracy
```

```python
#### Load data
```

```python
import pandas as pd
# df = pd.read_csv('data/smap_input.csv')
df = pd.read_csv('data/bacia-camargos.csv')

# Data cleaning
df['Ep'] = df['Ep'].str.replace(',', '.').astype('float')
df['Pr'] = df['Pr'].str.replace(',', '.').astype('float')

df.set_index(pd.to_datetime(df['data']), inplace=True)
df.drop('data', axis=1, inplace=True)

df.head()
```
```output (text/plain)
            Qobs    Ep    Pr
data                        
1995-01-01   204  4.94   4.3
1995-01-02   181  4.94   9.1
1995-01-03   176  4.94  22.8
1995-01-04   194  4.94   9.2
1995-01-05   198  4.94   1.7
```

```python
---
# Modelo Base
```

```python
#### Set parameters using middle of interval
```

```python
params_middle = dict(
    Str = 1050,  # Storage capacity (mm)
    Crec = 50,  # Example recharge coefficient
    Capc = 40.0,  # Example capacity percentage
    kep = 1.00, # 0.8  # Example parameter for evaporation adjustment
    K2t = 5.1,  # Example decay coefficient
    K1t = 5.1,  # Example decay coefficient for marginal storage
    K3t = 35.0,  # Another example decay coefficient
    Kkt = 105,  # Another example decay coefficient
    Ai = 4,  # Example threshold value
    H = 200.0,  # Example storage height or capacity
    
    # Non optimizable parameters
    Ad = 6279.0,  # Example area in square km (or appropriate units)
    Pcof = 1.0,  # Example precipitation coefficient
    Tuin = 20.0,  # Example initial moisture content
    Ebin = 45.0,  # Example baseflow initial value
    Supin = 1.0,  # Example surface flow initial value
)
```

```python
#### Set optimal parameters obtained by the ONS
```

```python
# Define default parameters
params_ons = dict(
    Ad = 6279.0,  # Example area in square km (or appropriate units)
    Str = 100.0,  # Storage capacity or other parameter (example value)
    K2t = 5.5,  # Example decay coefficient
    Crec = 100,  # Example recharge coefficient
    Ai = 2,  # Example threshold value
    Capc = 42.0,  # Example capacity percentage
    Kkt = 150,  # Another example decay coefficient
    Pcof = 1.0,  # Example precipitation coefficient
    Tuin = 20.0,  # Example initial moisture content
    Ebin = 45.0,  # Example baseflow initial value
    Supin = 1.0,  # Example surface flow initial value
    kep = 1.05153505864843, # 0.8  # Example parameter for evaporation adjustment
    H = 200.0,  # Example storage height or capacity
    K1t = 10.0,  # Example decay coefficient for marginal storage
    K3t = 10.0,  # Another example decay coefficient                
)

```

```python
#### Run model
```

```python
from modules.smap import ModeloSmapDiario

# start_date = '1995-08-01'
# end_date = '2000-08-01'

start_date = '2000-08-01'
end_date = '2030-01-01'

# Convert DataFrame columns to lists
Ep = df[start_date: end_date]['Ep'].tolist()
Pr = df[start_date: end_date]['Pr'].tolist()

# Call the function with the provided data
# result = ModeloSmapDiario(Ad, Str, K2t, Crec, Ai, Capc, Kkt, Ep, Pr, Pcof, Tuin, Ebin, Supin, kep, H, K1t, K3t)
result = ModeloSmapDiario(Ep=Ep, Pr=Pr, **params_middle)
# result = ModeloSmapDiario(Ep=Ep, Pr=Pr, **params_ons)
```

```python
#### Save result
```

```python
# Save result as pandas dataframe
result = pd.DataFrame(result)

# result_df.to_csv('data/optimization/output_base.csv', index=False)
# result_df.to_csv('data/optimization/output_ons.csv', index=False)
result.to_csv('data/optimization/output_base_val.csv', index=False)
# result_df.to_csv('data/optimization/output_ons_val.csv', index=False)

# Print the results
display(result.head(5))
```
```output (text/plain)
        Rsolo       Rsub      Rsup  Rsup2    P        Es        Er  Rec  \
0  210.000000  94.109247  0.108280    0.0  0.0  0.000000  0.000000  0.0   
1  209.130000  93.490040  0.094519    0.0  0.0  0.000000  0.870000  0.0   
2  208.821284  92.874907  0.082508    0.0  2.8  0.000000  3.108716  0.0   
3  208.791443  92.263822  0.072070    0.0  4.2  0.000048  4.229794  0.0   
4  208.005990  91.656758  0.062912    0.0  0.4  0.000000  1.185454  0.0   

         Ed  Emarg  Ed2        Eb          Q  
0  0.000000      0  0.0  0.000000   0.000000  
1  0.013760      0  0.0  0.619207  46.000000  
2  0.012012      0  0.0  0.615133  45.576835  
3  0.010485      0  0.0  0.611085  45.171768  
4  0.009159      0  0.0  0.607065  44.783173  
```

```python
---
# Calibração
```

```python
Análise gráfica de comportamento das séries geradas (ou simuladas) de vazão face aos valores observados.
```

```python
### Métricas de erro
```

```python
from modules.metrics import (
    nash_sutcliffe_efficacy,
    relative_error_coefficient,
    correlation_coefficient,
    mean_error,
    normalized_rmse,
    rmse
)

from sklearn.metrics import mean_squared_error
```

```python
### Rotinas de otimização automática
```

```python
#### Busca de Grade
```

```python
import time
import numpy as np
import pandas as pd
from sklearn.model_selection import ParameterGrid
from modules.smap import SmapModel

# Define the parameter grid based on the ranges provided
param_grid = {
    'H': np.linspace(0, 200, 5), # 0.96
    'Str': np.linspace(50, 2000, 5), # 1.19
    'K2t': np.linspace(0.2, 10, 5),  # 0.99
    'Crec': np.linspace(0, 100, 5), # 1.00
    'Ai': np.linspace(2, 5, 5), # 0.99
    'Capc': np.linspace(30, 50, 5), # 1.01
    'Kkt': np.linspace(30, 180, 5), # 1.02
    # 'K1t': np.linspace(0.2, 10, 5), # 0.96
    # 'K3t': np.linspace(10, 60, 5), # 0.96
    # 'kep': np.linspace(0.8, 1.2, 5), # 0.96
}

# Convert the parameter grid into a list of dictionaries
param_list = list(ParameterGrid(param_grid))
n_params = len(param_list)

start_date = '1995-08-01'
end_date = '2000-08-01'

data = df[start_date: end_date]
X = data[['Ep', 'Pr']]
y = data['Qobs'].values

# Initialize variables to store the best parameters and best score
best_score = float('inf')
# best_score = - float('inf')
best_params = None
best_result = None

# Example dataframe to hold results
results = []

# Initialize time counter
start = time.time()

# Perform the manual grid search
for i, params in enumerate(param_list):    
    
    # Initialize the model with the current set of parameters
    model = SmapModel(**{
        **params_ons,
        # **params_middle,
        **params,  # Unpack the current parameters from the grid
    })

    # Predict the output
    predictions = model.predict(X)

    # Calculate the score (Mean Squared Error in this case)
    mse = mean_squared_error(y, predictions)
    cef = nash_sutcliffe_efficacy(y, predictions)
    cer = relative_error_coefficient(y, predictions)
    
    # Collect results
    result = {}
    result['mse'] = mse
    result['cef'] = cef
    result['cer'] = cer
    result['soma_coef'] = cef + cer
    
    results.append(result)

    # Update the best score and parameters if the current score is better
    if result['mse'] < best_score:
        best_score = result['mse']
        best_params = params
        best_result = result

    time_passed = time.time() - start
    total_time = n_params * time_passed / (i + 1)
    time_left = total_time - time_passed
    
    time_passed = round(time_passed / 60, 1)
    total_time = round(total_time / 60, 1)
    time_left = round(time_left / 60, 1)
    
    if i + 1 in range(0, n_params, 100):
        print(f'processing: {i + 1}/{n_params} | {time_passed} m / {total_time} m | {time_left} m', end='\r')


# Convert results to a DataFrame
df_results = pd.DataFrame(results)

# Display the best parameters and the best score
print("Best parameters found: ", best_params)
print("Best score: ", best_score)

# Example heatmap (for Str vs. K2t)
# pivot_table = df_results.pivot('Str', 'K2t', 'score')
# sns.heatmap(pivot_table, annot=True, cmap='viridis')
# plt.title('Heatmap of MSE for Str vs. K2t')
# plt.show()

# sns.lineplot(x='Str', y='score', data=df_results)
# plt.title('MSE vs. Str')
# plt.xlabel('Str')
# plt.ylabel('MSE')
# plt.show()

# from mpl_toolkits.mplot3d import Axes3D
# from matplotlib import cm

# fig = plt.figure()
# ax = fig.add_subplot(111, projection='3d')
# ax.plot_trisurf(df_results['Str'], df_results['K2t'], df_results['score'], cmap=cm.viridis)
# ax.set_xlabel('Str')
# ax.set_ylabel('K2t')
# ax.set_zlabel('MSE')
# plt.title('3D Surface Plot of MSE')
# plt.show()
```

```python
'7-params-5-values': {'Ai': 2.0, 'Capc': 35.0, 'Crec': 100.0, 'H': 100.0, 'K2t': 10.0, 'Kkt': 30.0, 'Str': 50.0}
```

```python
#### Busca Randomizada
```

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform
from modules.smap import SmapModel
from modules.metrics import nash_sutcliffe_efficacy
from sklearn.metrics import mean_squared_error

def nash_sutcliffe_efficacy_score(estimator, X_test, y_test):
    y_pred = estimator.predict(X_test)
    return nash_sutcliffe_efficacy(y_test, y_pred)

def soma_coef_score(estimator, X_test, y_test):
    y_pred = estimator.predict(X_test)
    cef = nash_sutcliffe_efficacy(y_test, y_pred)
    cer = relative_error_coefficient(y_test, y_pred)
    return - (cef + cer)
    
start_date = '1995-08-01'
end_date = '2000-08-01'

data = df[start_date: end_date]
X = data[['Ep', 'Pr']]
y = data['Qobs'].values

# Define the parameter distributions (using a wide range with fewer values for random sampling)
param_distributions = {
    'H': uniform(0, 200), 
    'Str': uniform(50, 2000), 
    'K2t': uniform(0.2, 10),  
    'Crec': uniform(0, 100), 
    'Ai': uniform(2, 5), 
    'Capc': uniform(30, 50), 
    'Kkt': uniform(30, 180), 
    'K3t': uniform(10, 60), 
    'kep': uniform(0.8, 1.2),
}

# Initialize the model
model = SmapModel(**params_ons)

# Perform Randomized Search
random_search = RandomizedSearchCV(model, param_distributions, n_iter=5000, scoring='neg_mean_squared_error', error_score='raise', cv=2, verbose=1)
random_search.fit(X, y)

# Get the best parameters
print(f"Best Parameters: {random_search.best_params_}")
print(f"Best Score: {random_search.best_score_}")

```

```python
#### Bayesian Optimization (with libraries like skopt or hyperopt)
```

```python
# !pip install scikit-optimize

from skopt import gp_minimize
from skopt.space import Real
from skopt.utils import use_named_args
from modules.smap import SmapModel
from sklearn.metrics import mean_squared_error

start_date = '1995-08-01'
end_date = '2000-08-01'

data = df[start_date: end_date]
X = data[['Ep', 'Pr']]
y = data['Qobs'].values

# Define the search space
search_space = [
    Real(0, 200, name='H'),
    Real(50, 2000, name='Str'),
    Real(0.2, 10, name='K2t'),
    Real(0, 100, name='Crec'),
    Real(2, 5, name='Ai'),
    Real(30, 50, name='Capc'),
    Real(30, 180, name='Kkt'),
    Real(10, 60, name='K3t'),
    Real(0.8, 1.2, name='kep'),
]

# Objective function to minimize
@use_named_args(search_space)
def objective(**params):
    model = SmapModel(**{**params_ons, **params})
    predictions = model.predict(X)
    mse = mean_squared_error(y, predictions)
    return mse

# Perform Bayesian optimization
result = gp_minimize(objective, search_space, n_calls=250, random_state=0, verbose=1)

# Get the best parameters
best_params = {space.name: value for space, value in zip(result.space, result.x)}
print(f"Best Parameters: {best_params}")
print(f"Best Score: {result.fun}")

```

```python
50: {'H': 199.93598938946454,
 'Str': 50.0,
 'K2t': 9.974586382586164,
 'Crec': 25.19050814571343,
 'Ai': 5.0,
 'Capc': 50.0,
 'Kkt': 30.0,
 'K3t': 46.33897974946203,
 'kep': 0.8}

250: {'H': 111.99016824287398,
 'Str': 50.0,
 'K2t': 9.992900868595116,
 'Crec': 100.0,
 'Ai': 2.0,
 'Capc': 46.762652004145274,
 'Kkt': 179.53755426503005,
 'K3t': 10.0,
 'kep': 1.168066284489991}
```

```python
#### Genetic Algorithms (e.g., using DEAP or tpot)
```

```python
# !pip install deap
from modules.smap import SmapModel
from deap import base, creator, tools, algorithms
from sklearn.metrics import mean_squared_error
import random

start_date = '1995-08-01'
end_date = '2000-08-01'

data = df[start_date: end_date]
X = data[['Ep', 'Pr']]
y = data['Qobs'].values

# Define the problem as minimization
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)

# Define the toolbox
toolbox = base.Toolbox()
toolbox.register("H", random.uniform, 0, 200)
toolbox.register("Str", random.uniform, 50, 2000)
toolbox.register("K2t", random.uniform, 0.2, 10)
toolbox.register("Crec", random.uniform, 0, 100)
toolbox.register("Ai", random.uniform, 2, 5)
toolbox.register("Capc", random.uniform, 30, 50)
toolbox.register("Kkt", random.uniform, 30, 180)
toolbox.register("K3t", random.uniform, 10, 60)
toolbox.register("kep", random.uniform, 0.8, 1.2)

# Register individual and population
toolbox.register("individual", tools.initCycle, creator.Individual,
                 (toolbox.H, toolbox.Str, toolbox.K2t, toolbox.Crec, toolbox.Ai, toolbox.Capc, toolbox.Kkt, toolbox.K3t, toolbox.kep))
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

# Define the evaluation function
def evaluate(individual):
    params = {
        'H': individual[0],
        'Str': individual[1],
        'K2t': individual[2],
        'Crec': individual[3],
        'Ai': individual[4],
        'Capc': individual[5],
        'Kkt': individual[6],
        'K3t': individual[7],
        'kep': individual[8]
    }
    model = SmapModel(**{**params_ons, **params})
    predictions = model.predict(X)
    try:
        mse = mean_squared_error(y, predictions)
    except:
        print(y)
        print(predictions)
        raise
    return (mse,)

toolbox.register("evaluate", evaluate)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)
toolbox.register("select", tools.selTournament, tournsize=3)

# Perform the genetic algorithm
population = toolbox.population(n=100)
algorithms.eaSimple(population, toolbox, cxpb=0.7, mutpb=0.2, ngen=150, verbose=True)

# Get the best individual
individual = tools.selBest(population, 1)[0]
best_params = {
    'H': individual[0],
    'Str': individual[1],
    'K2t': individual[2],
    'Crec': individual[3],
    'Ai': individual[4],
    'Capc': individual[5],
    'Kkt': individual[6],
    'K3t': individual[7],
    'kep': individual[8]
}
print(f"Best parameters:")
display(best_params)

```
```output (text/plain)
{'H': 122.04428611529477,
 'Str': 74.68942508783357,
 'K2t': 18.279153532495116,
 'Crec': 35.48098498635494,
 'Ai': -0.030644571937704496,
 'Capc': 37.52042131093961,
 'Kkt': 86.3982466820696,
 'K3t': 45.866155905919186,
 'kep': 1.8303829697039575}
```

```python
### Gerando valores com parametros da calibração
```

```python
display({'Ai': 2.0, 'Capc': 35.0, 'Crec': 100.0, 'H': 100.0, 'K2t': 10.0, 'Kkt': 30.0, 'Str': 50.0})
```
```output (text/plain)
{'Ai': 2.0,
 'Capc': 35.0,
 'Crec': 100.0,
 'H': 100.0,
 'K2t': 10.0,
 'Kkt': 30.0,
 'Str': 50.0}
```

```python
from modules.smap import ModeloSmapDiario

# {'H': 79.20954889227983, 'Str': 64.16121391492987, 'K2t': 12.372076659368517, 'Crec': 44.81669746653843, 'Ai': -0.27342661871850227, 'Capc': 23.56561613941976, 'Kkt': 88.32465652645809, 'K3t': 60.17455705168745, 'kep': 0.02306651721594341}
params = {**params_ons, **{
 'Ai': 2.0,
 'Capc': 35.0,
 'Crec': 100.0,
 'H': 100.0,
 'K2t': 10.0,
 'Kkt': 30.0,
 'Str': 50.0}
}
# {'H': 97.77804683224933,
#  'Str': 111.66816046309711,
#  'K2t': 13.869444072622693,
#  'Crec': 133.14938081167017,
#  'Ai': -7.330784521394884,
#  'Capc': 25.11493570120567,
#  'Kkt': 134.5127058863939,
#  'K3t': 72.81383453347158,
#  'kep': -0.04973625808648212} # genetic: 80


# start_date = '1995-08-01'
# end_date = '2000-08-01'

start_date = '2000-08-01'
end_date = '2030-01-01'

# Convert DataFrame columns to lists
Ep = df[start_date: end_date]['Ep'].tolist()
Pr = df[start_date: end_date]['Pr'].tolist()

# Call the function with the provided data
result = ModeloSmapDiario(
    Ep=Ep,
    Pr=Pr,    
    **{
    **params_ons,
    **params,  # Unpack the best parameters from the grid
})
```

```python
#### Salvando Resultado
```

```python
# Save result as pandas dataframe
result_df = pd.DataFrame(result)

# result_df.to_csv('data/optimization/output_opt_grid.csv', index=False)
# result_df.to_csv('data/optimization/output_opt_randomized.csv', index=False)
# result_df.to_csv('data/optimization/output_opt_bayesian.csv', index=False)
# result_df.to_csv('data/optimization/output_opt_genetic.csv', index=False)

result_df.to_csv('data/optimization/output_opt_grid_val.csv', index=False)
# result_df.to_csv('data/optimization/output_opt_randomized_val.csv', index=False)
# result_df.to_csv('data/optimization/output_opt_bayesian_val.csv', index=False)
# result_df.to_csv('data/optimization/output_opt_genetic_val.csv', index=False)

# Print the results
display(result_df.head(5))
```
```output (text/plain)
       Rsolo       Rsub      Rsup  Rsup2    P        Es        Er  Rec  \
0  10.000000  27.110597  0.205477    0.0  0.0  0.000000  0.000000  0.0   
1   9.130000   0.000000  0.191716    0.0  0.0  0.000000  0.870000  0.0   
2   8.844165   0.000000  0.194237    0.0  2.8  0.015359  3.070476  0.0   
3   8.797887   0.000000  0.292863    0.0  4.2  0.111634  4.134644  0.0   
4   8.102854   0.000000  0.273251    0.0  0.4  0.000000  1.095033  0.0   

         Ed  Emarg  Ed2        Eb          Q  
0  0.000000    0.0  0.0  0.000000   0.000000  
1  0.013760    0.0  0.0  0.619207  46.000000  
2  0.012839    0.0  0.0  0.000000   0.933033  
3  0.013007    0.0  0.0  0.000000   0.945298  
4  0.019612    0.0  0.0  0.000000   1.425289  
```

```python
---
# Análise gráfica de comportamento das séries geradas
```

```python
#### Métricas de Erro
```

```python
Fonte: http://www.coc.ufrj.br/pt/dissertacoes-de-mestrado/105-msc-pt-2005/1992-rafael-carneiro-di-bello
```

```python
![image.png](attachment:6f45235b-59f7-4b39-824d-0515650620ae.png)
```

```python
### Curvas de permanência
```

```python
A "curva de permanência" é um gráfico que mostra a probabilidade de uma determinada vazão ser igualada ou excedida.
```

```python
### Gráfico de dispersão
```

```python
Este tipo de gráfico é útil para analisar a correlação entre as vazões observadas e as geradas.

- **Gráfico de Dispersão**:
  - O gráfico plota pontos para cada par de valores de vazão observada e gerada.
  - As previsões dos diferentes modelos são diferenciadas por cor e legendadas.
- **Linha de Perfeição**:
  - A linha preta tracejada (`Linha de Perfeição`) representa onde os valores gerados seriam exatamente iguais aos valores observados. Isso ajuda a visualizar o quão próximo as previsões estão dos valores reais.

Esse gráfico permite avaliar visualmente o desempenho dos modelos de previsão em relação aos dados observados.
```

```python
### Gráfico de Resíduos
```

```python
Mostra a diferença entre as vazões geradas e as vazões observadas (resíduos) ao longo do tempo.

Esse tipo de gráfico é útil para identificar padrões ou desvios sistemáticos nos erros de previsão.
```

```python
#### Load data
```

```python
import pandas as pd
# df = pd.read_csv('data/smap_input.csv')
df = pd.read_csv('data/bacia-camargos.csv')

# Data cleaning
df['Ep'] = df['Ep'].str.replace(',', '.').astype('float')
df['Pr'] = df['Pr'].str.replace(',', '.').astype('float')

df.set_index(pd.to_datetime(df['data']), inplace=True)
df.drop('data', axis=1, inplace=True)

df.head()
```
```output (text/plain)
            Qobs    Ep    Pr
data                        
1995-01-01   204  4.94   4.3
1995-01-02   181  4.94   9.1
1995-01-03   176  4.94  22.8
1995-01-04   194  4.94   9.2
1995-01-05   198  4.94   1.7
```

```python
#### Recarregar resultados
```

```python
import pandas as pd
import numpy as np

output_base = pd.read_csv('data/optimization/output_base.csv')
output_ons = pd.read_csv('data/optimization/output_ons.csv')
output_opt_grid = pd.read_csv('data/optimization/output_opt_grid.csv')
output_opt_bay = pd.read_csv('data/optimization/output_opt_bayesian.csv')
output_opt_rand = pd.read_csv('data/optimization/output_opt_randomized.csv')
output_opt_gen = pd.read_csv('data/optimization/output_opt_genetic.csv')

output_base.columns += ' - BASE'
output_ons.columns += ' - ONS'
output_opt_grid.columns += ' - OPT GRID'
output_opt_rand.columns += ' - OPT RAND'
output_opt_bay.columns += ' - OPT BAY'
output_opt_gen.columns += ' - OPT GEN'

preds = pd.concat([output_base, output_ons, output_opt_grid, output_opt_rand, output_opt_bay, output_opt_gen], axis=1)

start_date = '1995-08-01'
end_date = '2000-08-01'
data = df[start_date: end_date]

preds.index = data.index
preds.index.name = 'index'
preds['Q - OBS'] = data['Qobs']

preds['Q - OPT'] = preds['Q - OPT GEN']
preds['Rsub - OPT'] = preds['Rsub - OPT GEN']
preds['Rsup - OPT'] = preds['Rsup - OPT GEN']

preds.head()
```
```output (text/plain)
            Rsolo - BASE  Rsub - BASE  Rsup - BASE  Rsup2 - BASE  P - BASE  \
index                                                                        
1995-08-01    210.000000    94.109247     0.108280           0.0       0.0   
1995-08-02    209.130000    93.490040     0.094519           0.0       0.0   
1995-08-03    208.263604    92.874907     0.082508           0.0       0.0   
1995-08-04    207.400798    92.263822     0.072023           0.0       0.0   
1995-08-05    206.541566    91.656758     0.062870           0.0       0.0   

            Es - BASE  Er - BASE  Rec - BASE  Ed - BASE  Emarg - BASE  ...  \
index                                                                  ...   
1995-08-01        0.0   0.000000         0.0   0.000000             0  ...   
1995-08-02        0.0   0.870000         0.0   0.013760             0  ...   
1995-08-03        0.0   0.866396         0.0   0.012012             0  ...   
1995-08-04        0.0   0.862806         0.0   0.010485             0  ...   
1995-08-05        0.0   0.859232         0.0   0.009153             0  ...   

            Rec - OPT GEN  Ed - OPT GEN  Emarg - OPT GEN  Ed2 - OPT GEN  \
index                                                                     
1995-08-01            0.0      0.000000              0.0            0.0   
1995-08-02            0.0      0.013760              0.0            0.0   
1995-08-03            0.0      0.062128              0.0            0.0   
1995-08-04            0.0      0.106224              0.0            0.0   
1995-08-05            0.0      0.146409              0.0            0.0   

            Eb - OPT GEN  Q - OPT GEN  Q - OBS    Q - OPT  Rsub - OPT  \
index                                                                   
1995-08-01      0.000000     0.000000       46   0.000000   80.870069   
1995-08-02      0.619207    46.000000       46  46.000000    0.000000   
1995-08-03      0.000000     4.515064       46   4.515064    0.000000   
1995-08-04      0.000000     7.719654       46   7.719654    0.000000   
1995-08-05      0.000000    10.640103       46  10.640103    0.000000   

            Rsup - OPT  
index                   
1995-08-01    0.167530  
1995-08-02    0.756408  
1995-08-03    1.293273  
1995-08-04    1.782535  
1995-08-05    2.228237  

[5 rows x 82 columns]
```

```python
### Métricas de erro
```

```python
import pandas as pd

from modules.metrics import (
    nash_sutcliffe_efficacy,
    relative_error_coefficient,
    correlation_coefficient,
    mean_error,
    normalized_rmse,
    rmse
)
from sklearn.metrics import mean_squared_error
```

```python
#### Metrics - CALIBRATION
```

```python
y_true = preds['Q - OBS']
columns = ['Q - BASE', 'Q - ONS', 'Q - OPT GRID', 'Q - OPT RAND', 'Q - OPT BAY', 'Q - OPT GEN']

stats = []
for pred in columns:
    y_pred = preds[pred]

    # Calculate the score (Mean Squared Error in this case)
    mse = mean_squared_error(y_true, y_pred)
    cef = nash_sutcliffe_efficacy(y_true, y_pred)
    cer = relative_error_coefficient(y_true, y_pred)
    soma_coef = cef + cer
    
    cc = correlation_coefficient(y_true, y_pred)
    me = mean_error(y_true, y_pred)
    rmse_norm = normalized_rmse(y_true, y_pred)
    RMSE = rmse(y_true, y_pred)

    stats.append({
        'cef': cef,
        'cer': cer,
        'soma_coef': soma_coef,
        'cc': cc,
        'me': me,
        'rmse_norm': rmse_norm,
        'rmse': RMSE}
    )

stats = pd.DataFrame(stats, index=columns)
display(stats.T)

```
```output (text/plain)
            Q - BASE    Q - ONS  Q - OPT GRID  Q - OPT RAND  Q - OPT BAY  \
cef         0.316289   0.793380      0.627835      0.482649     0.596397   
cer         0.651888   0.871702      0.669828      0.666273     0.617783   
soma_coef   0.968177   1.665082      1.297663      1.148922     1.214180   
cc          0.634245   0.904831      0.869941      0.888134     0.882859   
me         25.853598  -0.028345     10.806848     -2.055290    15.456251   
rmse_norm   0.683337   0.206507      0.371962      0.517068     0.403382   
rmse       72.827808  40.035637     53.731484     63.351000    55.954900   

           Q - OPT GEN  
cef           0.851605  
cer           0.811392  
soma_coef     1.662998  
cc            0.923651  
me            0.528001  
rmse_norm     0.148314  
rmse         33.928933  
```

```python
#### Data Visualization
```

```python
from modules.visu import report, interactive_report

# report(preds)
figures = interactive_report(preds)
```

```python
#### Save figures as html
```

```python
import plotly.graph_objects as go
import plotly.io as pio

# Combine figures into a single HTML file
with open('calibracao.html', 'w') as out:
    for fig in figures:
        out.write(fig.to_html(full_html=False, include_plotlyjs='cdn'))

```

```python
#### Balanço Anual de P, E e Q
```

```python
import matplotlib.pyplot as plt

preds = pd.concat([preds, df.loc[preds.index]], axis=1)

A_bacia = params_ons['Ad'] * 1e6  # Área da bacia em metros quadrados (ajuste com base nos dados reais)

# Convertendo Pr e Ep de mm/dia para m³/dia
preds['Pr_m3'] = preds['Pr'] * A_bacia / 1000  # Pr convertida para m³/dia
preds['Ep_m3'] = preds['Ep'] * A_bacia / 1000  # Ep convertida para m³/dia

# Convertendo as vazões de m³/s para m³/dia
preds['Q - OBS_m3_dia'] = preds['Q - OBS'] * 86400  # Vazão observada em m³/dia
preds['Q - OPT_m3_dia'] = preds['Q - OPT'] * 86400  # Vazão otimizada em m³/dia

# Agrupamento anual com os valores já convertidos
df_annual = preds.resample('Y').sum()

# Gráfico de balanço hídrico anual
df_annual[['Pr_m3', 'Ep_m3', 'Q - OBS_m3_dia', 'Q - OPT_m3_dia']].plot(kind='bar',figsize=(10, 6))
plt.title('Balanço Hídrico Anual (m³/ano)')
plt.ylabel('Valores Acumulados Anuais (m³)')
plt.xlabel('Ano')
plt.show()

```
```output (text/plain)
<Figure size 1000x600 with 1 Axes>
```

```python
#### Variação dos níveis dos reservatórios superficiais e subterrâneos
```

```python
import matplotlib.pyplot as plt
import pandas as pd

# Plotando a variação dos níveis dos reservatórios superficial e subterrâneo
plt.figure(figsize=(14, 8))

# Plot para os reservatórios superficiais
plt.subplot(2, 1, 1)
plt.plot(preds.index, preds['Rsup - BASE'], label='Reservatório Superficial BASE', linestyle=':')
plt.plot(preds.index, preds['Rsup - ONS'], label='Reservatório Superficial ONS', linestyle='-.')
plt.plot(preds.index, preds['Rsup - OPT'], label='Reservatório Superficial OPT', linestyle='--')
plt.title('Variação dos Níveis do Reservatório Superficial')
plt.ylabel('Nível do Reservatório Superficial (m³)')
plt.legend()

# Plot para os reservatórios subterrâneos
plt.subplot(2, 1, 2)
plt.plot(preds.index, preds['Rsub - BASE'], label='Reservatório Subterrâneo BASE', linestyle=':')
plt.plot(preds.index, preds['Rsub - ONS'], label='Reservatório Subterrâneo ONS', linestyle='-.')
plt.plot(preds.index, preds['Rsub - OPT'], label='Reservatório Subterrâneo OPT', linestyle='--')
plt.title('Variação dos Níveis do Reservatório Subterrâneo')
plt.xlabel('Data')
plt.ylabel('Nível do Reservatório Subterrâneo (m³)')
plt.legend()

# Ajustar o layout para não sobrepor os gráficos
plt.tight_layout()
plt.show()

```
```output (text/plain)
<Figure size 1400x800 with 2 Axes>
```

```python
---
# Validação
```

```python
#### Load data
```

```python
import pandas as pd
# df = pd.read_csv('data/smap_input.csv')
df = pd.read_csv('data/bacia-camargos.csv')

# Data cleaning
df['Ep'] = df['Ep'].str.replace(',', '.').astype('float')
df['Pr'] = df['Pr'].str.replace(',', '.').astype('float')

df.set_index(pd.to_datetime(df['data']), inplace=True)
df.drop('data', axis=1, inplace=True)

df.head()
```
```output (text/plain)
            Qobs    Ep    Pr
data                        
1995-01-01   204  4.94   4.3
1995-01-02   181  4.94   9.1
1995-01-03   176  4.94  22.8
1995-01-04   194  4.94   9.2
1995-01-05   198  4.94   1.7
```

```python
#### Recarregar resultados
```

```python
import pandas as pd
import numpy as np

output_base = pd.read_csv('data/optimization/output_base_val.csv')
output_ons = pd.read_csv('data/optimization/output_ons_val.csv')
output_opt_rand = pd.read_csv('data/optimization/output_opt_randomized_val.csv')
output_opt_gen = pd.read_csv('data/optimization/output_opt_genetic_val.csv')

output_base.columns += ' - BASE'
output_ons.columns += ' - ONS'
output_opt_rand.columns += ' - OPT RAND'
output_opt_gen.columns += ' - OPT GEN'

preds = pd.concat([output_base, output_ons, output_opt_rand, output_opt_gen], axis=1)

# start_date = '1995-08-01'
# end_date = '2000-08-01'
start_date = '2000-08-01'
end_date = '2030-01-01'
data = df[start_date: end_date]

preds.index = data.index
preds.index.name = 'index'
preds['Q - OBS'] = data['Qobs']

preds['Q - OPT'] = preds['Q - OPT GEN']
preds['Rsub - OPT'] = preds['Rsub - OPT GEN']
preds['Rsup - OPT'] = preds['Rsup - OPT GEN']

preds.head()
```
```output (text/plain)
            Rsolo - BASE  Rsub - BASE  Rsup - BASE  Rsup2 - BASE  P - BASE  \
index                                                                        
2000-08-01    210.000000    94.109247     0.108280           0.0       0.0   
2000-08-02    209.130000    93.490040     0.094519           0.0       0.0   
2000-08-03    208.821284    92.874907     0.082508           0.0       2.8   
2000-08-04    208.791443    92.263822     0.072070           0.0       4.2   
2000-08-05    208.005990    91.656758     0.062912           0.0       0.4   

            Es - BASE  Er - BASE  Rec - BASE  Ed - BASE  Emarg - BASE  ...  \
index                                                                  ...   
2000-08-01   0.000000   0.000000         0.0   0.000000             0  ...   
2000-08-02   0.000000   0.870000         0.0   0.013760             0  ...   
2000-08-03   0.000000   3.108716         0.0   0.012012             0  ...   
2000-08-04   0.000048   4.229794         0.0   0.010485             0  ...   
2000-08-05   0.000000   1.185454         0.0   0.009159             0  ...   

            Rec - OPT GEN  Ed - OPT GEN  Emarg - OPT GEN  Ed2 - OPT GEN  \
index                                                                     
2000-08-01            0.0      0.000000              0.0            0.0   
2000-08-02            0.0      0.013760              0.0            0.0   
2000-08-03            0.0      0.062128              0.0            0.0   
2000-08-04            0.0      0.136616              0.0            0.0   
2000-08-05            0.0      0.221240              0.0            0.0   

            Eb - OPT GEN  Q - OPT GEN  Q - OBS    Q - OPT  Rsub - OPT  \
index                                                                   
2000-08-01      0.000000     0.000000       56   0.000000   80.870069   
2000-08-02      0.619207    46.000000       56  46.000000    0.000000   
2000-08-03      0.000000     4.515064       56   4.515064    0.000000   
2000-08-04      0.000000     9.928365       58   9.928365    0.000000   
2000-08-05      0.000000    16.078298       62  16.078298    0.000000   

            Rsup - OPT  
index                   
2000-08-01    0.167530  
2000-08-02    0.756408  
2000-08-03    1.663298  
2000-08-04    2.693595  
2000-08-05    3.104362  

[5 rows x 56 columns]
```

```python
#### Metrics - VALIDATION
```

```python
y_true = preds['Q - OBS']
columns = ['Q - BASE', 'Q - ONS', 'Q - OPT RAND', 'Q - OPT GEN']

stats = []
for pred in columns:
    y_pred = preds[pred]

    # Calculate the score (Mean Squared Error in this case)
    mse = mean_squared_error(y_true, y_pred)
    cef = nash_sutcliffe_efficacy(y_true, y_pred)
    cer = relative_error_coefficient(y_true, y_pred)
    soma_coef = cef + cer
    
    cc = correlation_coefficient(y_true, y_pred)
    me = mean_error(y_true, y_pred)
    rmse_norm = normalized_rmse(y_true, y_pred)
    RMSE = rmse(y_true, y_pred)

    stats.append({
        'cef': cef,
        'cer': cer,
        'soma_coef': soma_coef,
        'cc': cc,
        'me': me,
        'rmse_norm': rmse_norm,
        'rmse': RMSE}
    )

stats = pd.DataFrame(stats, index=columns)
display(stats.T)

```
```output (text/plain)
            Q - BASE    Q - ONS  Q - OPT RAND  Q - OPT GEN
cef         0.296795   0.898135      0.453340     0.854966
cer         0.649947   0.856959      0.562850     0.807230
soma_coef   0.946741   1.755094      1.016191     1.662195
cc          0.601270   0.957205      0.917602     0.940256
me         18.175795  -6.738186      0.969686    -4.042630
rmse_norm   0.702946   0.101828      0.546458     0.144981
rmse       62.102310  23.636318     54.755173    28.203450
```

```python
#### Data Visualization
```

```python
from modules.visu import interactive_report

# report(preds)
interactive_report(preds)
```

```python
#### Balanço Anual de P, E e Q
```

```python
import matplotlib.pyplot as plt

preds = pd.concat([preds, df.loc[preds.index]], axis=1)

A_bacia = params_ons['Ad'] * 1e6  # Área da bacia em metros quadrados (ajuste com base nos dados reais)

# Convertendo Pr e Ep de mm/dia para m³/dia
preds['Pr_m3'] = preds['Pr'] * A_bacia / 1000  # Pr convertida para m³/dia
preds['Ep_m3'] = preds['Ep'] * A_bacia / 1000  # Ep convertida para m³/dia

# Convertendo as vazões de m³/s para m³/dia
preds['Q - OBS_m3_dia'] = preds['Q - OBS'] * 86400  # Vazão observada em m³/dia
preds['Q - OPT_m3_dia'] = preds['Q - OPT'] * 86400  # Vazão otimizada em m³/dia

# Agrupamento anual com os valores já convertidos
df_annual = preds.resample('Y').sum()

# Gráfico de balanço hídrico anual
df_annual[['Pr_m3', 'Ep_m3', 'Q - OBS_m3_dia', 'Q - OPT_m3_dia']].plot(kind='bar',figsize=(10, 6))
plt.title('Balanço Hídrico Anual (m³/ano)')
plt.ylabel('Valores Acumulados Anuais (m³)')
plt.xlabel('Ano')
plt.show()

```
```output (text/plain)
<Figure size 1000x600 with 1 Axes>
```

```python
#### Variação dos níveis dos reservatórios superficiais e subterrâneos
```

```python
import matplotlib.pyplot as plt
import pandas as pd

# Plotando a variação dos níveis dos reservatórios superficial e subterrâneo
plt.figure(figsize=(14, 8))

# Plot para os reservatórios superficiais
plt.subplot(2, 1, 1)
plt.plot(preds.index, preds['Rsup - BASE'], label='Reservatório Superficial BASE', linestyle=':')
plt.plot(preds.index, preds['Rsup - ONS'], label='Reservatório Superficial ONS', linestyle='-.')
plt.plot(preds.index, preds['Rsup - OPT'], label='Reservatório Superficial OPT', linestyle='--')
plt.title('Variação dos Níveis do Reservatório Superficial')
plt.ylabel('Nível do Reservatório Superficial (m³)')
plt.legend()

# Plot para os reservatórios subterrâneos
plt.subplot(2, 1, 2)
plt.plot(preds.index, preds['Rsub - BASE'], label='Reservatório Subterrâneo BASE', linestyle=':')
plt.plot(preds.index, preds['Rsub - ONS'], label='Reservatório Subterrâneo ONS', linestyle='-.')
plt.plot(preds.index, preds['Rsub - OPT'], label='Reservatório Subterrâneo OPT', linestyle='--')
plt.title('Variação dos Níveis do Reservatório Subterrâneo')
plt.xlabel('Data')
plt.ylabel('Nível do Reservatório Subterrâneo (m³)')
plt.legend()

# Ajustar o layout para não sobrepor os gráficos
plt.tight_layout()
plt.show()

```
```output (text/plain)
<Figure size 1400x800 with 2 Axes>
```